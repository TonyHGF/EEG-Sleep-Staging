{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_edf import plot_signals\n",
    "from read_result import read_result_file\n",
    "from read_result import plot_sleep_stages\n",
    "from split_signal import split_edf_by_annotations\n",
    "from split_signal import split_edf_by_30s\n",
    "from sklearn.decomposition import PCA\n",
    "import processing_data\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_number = 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393345, 105)\n",
      "(393345,)\n"
     ]
    }
   ],
   "source": [
    "X = np.empty((0,feature_number))\n",
    "y = np.empty((0,))\n",
    "for dirname, _, filenames in os.walk('./result'):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirname, filename)\n",
    "        file = np.load(file_path)\n",
    "        X = np.concatenate((X, file['features']))\n",
    "        y = np.concatenate((y, file['labels']))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393345, 82)\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components= 0.999).fit(X_scaled)\n",
    "X_pca = pca.transform(X_scaled)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(393345, 82) (393345,)\n"
     ]
    }
   ],
   "source": [
    "model_X = X_pca\n",
    "model_y = y\n",
    "print(model_X.shape, model_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2. 3. 4. 5. 6.]\n"
     ]
    }
   ],
   "source": [
    "# find how many kinds of values in y\n",
    "y_values = np.unique(model_y)\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with learning rate: 0.02 and channel: 32\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4641\u001b[0m       \u001b[32m0.8851\u001b[0m        \u001b[35m0.3390\u001b[0m  4.1248\n",
      "      2        \u001b[36m0.3256\u001b[0m       \u001b[32m0.8955\u001b[0m        \u001b[35m0.3019\u001b[0m  3.7066\n",
      "      3        \u001b[36m0.3032\u001b[0m       \u001b[32m0.8991\u001b[0m        \u001b[35m0.2888\u001b[0m  3.6971\n",
      "      4        \u001b[36m0.2926\u001b[0m       \u001b[32m0.9009\u001b[0m        \u001b[35m0.2818\u001b[0m  3.9903\n",
      "      5        \u001b[36m0.2857\u001b[0m       \u001b[32m0.9024\u001b[0m        \u001b[35m0.2769\u001b[0m  4.0470\n",
      "      6        \u001b[36m0.2806\u001b[0m       \u001b[32m0.9037\u001b[0m        \u001b[35m0.2729\u001b[0m  3.9813\n",
      "      7        \u001b[36m0.2764\u001b[0m       \u001b[32m0.9048\u001b[0m        \u001b[35m0.2699\u001b[0m  3.9030\n",
      "      8        \u001b[36m0.2730\u001b[0m       \u001b[32m0.9054\u001b[0m        \u001b[35m0.2675\u001b[0m  3.9313\n",
      "      9        \u001b[36m0.2699\u001b[0m       \u001b[32m0.9062\u001b[0m        \u001b[35m0.2655\u001b[0m  3.9211\n",
      "     10        \u001b[36m0.2673\u001b[0m       \u001b[32m0.9068\u001b[0m        \u001b[35m0.2639\u001b[0m  3.8869\n",
      "     11        \u001b[36m0.2650\u001b[0m       \u001b[32m0.9069\u001b[0m        \u001b[35m0.2624\u001b[0m  3.8222\n",
      "     12        \u001b[36m0.2631\u001b[0m       \u001b[32m0.9076\u001b[0m        \u001b[35m0.2611\u001b[0m  3.8888\n",
      "     13        \u001b[36m0.2610\u001b[0m       \u001b[32m0.9080\u001b[0m        \u001b[35m0.2600\u001b[0m  3.8844\n",
      "     14        \u001b[36m0.2594\u001b[0m       \u001b[32m0.9083\u001b[0m        \u001b[35m0.2591\u001b[0m  4.1428\n",
      "     15        \u001b[36m0.2577\u001b[0m       \u001b[32m0.9086\u001b[0m        \u001b[35m0.2580\u001b[0m  4.2332\n",
      "     16        \u001b[36m0.2562\u001b[0m       \u001b[32m0.9088\u001b[0m        \u001b[35m0.2571\u001b[0m  4.1876\n",
      "     17        \u001b[36m0.2548\u001b[0m       \u001b[32m0.9090\u001b[0m        \u001b[35m0.2561\u001b[0m  4.2399\n",
      "     18        \u001b[36m0.2535\u001b[0m       \u001b[32m0.9092\u001b[0m        \u001b[35m0.2554\u001b[0m  4.1652\n",
      "     19        \u001b[36m0.2523\u001b[0m       \u001b[32m0.9095\u001b[0m        \u001b[35m0.2547\u001b[0m  4.1744\n",
      "     20        \u001b[36m0.2513\u001b[0m       \u001b[32m0.9097\u001b[0m        \u001b[35m0.2542\u001b[0m  4.1446\n",
      "     21        \u001b[36m0.2502\u001b[0m       \u001b[32m0.9099\u001b[0m        \u001b[35m0.2536\u001b[0m  4.1772\n",
      "     22        \u001b[36m0.2492\u001b[0m       0.9099        \u001b[35m0.2531\u001b[0m  4.2563\n",
      "     23        \u001b[36m0.2483\u001b[0m       \u001b[32m0.9101\u001b[0m        \u001b[35m0.2527\u001b[0m  4.2055\n",
      "     24        \u001b[36m0.2473\u001b[0m       \u001b[32m0.9104\u001b[0m        \u001b[35m0.2523\u001b[0m  4.2697\n",
      "     25        \u001b[36m0.2465\u001b[0m       \u001b[32m0.9107\u001b[0m        \u001b[35m0.2519\u001b[0m  4.2006\n",
      "     26        \u001b[36m0.2457\u001b[0m       \u001b[32m0.9108\u001b[0m        \u001b[35m0.2518\u001b[0m  4.1108\n",
      "     27        \u001b[36m0.2448\u001b[0m       \u001b[32m0.9109\u001b[0m        \u001b[35m0.2513\u001b[0m  4.0709\n",
      "     28        \u001b[36m0.2440\u001b[0m       0.9108        \u001b[35m0.2513\u001b[0m  4.0467\n",
      "     29        \u001b[36m0.2432\u001b[0m       \u001b[32m0.9111\u001b[0m        \u001b[35m0.2506\u001b[0m  3.9915\n",
      "     30        \u001b[36m0.2425\u001b[0m       0.9111        \u001b[35m0.2506\u001b[0m  3.9887\n",
      "     31        \u001b[36m0.2417\u001b[0m       \u001b[32m0.9115\u001b[0m        \u001b[35m0.2503\u001b[0m  3.9968\n",
      "     32        \u001b[36m0.2410\u001b[0m       0.9115        \u001b[35m0.2501\u001b[0m  4.1275\n",
      "     33        \u001b[36m0.2404\u001b[0m       \u001b[32m0.9117\u001b[0m        \u001b[35m0.2500\u001b[0m  4.4096\n",
      "     34        \u001b[36m0.2398\u001b[0m       \u001b[32m0.9118\u001b[0m        \u001b[35m0.2497\u001b[0m  4.1277\n",
      "     35        \u001b[36m0.2392\u001b[0m       \u001b[32m0.9119\u001b[0m        \u001b[35m0.2493\u001b[0m  3.9399\n",
      "     36        \u001b[36m0.2386\u001b[0m       0.9118        \u001b[35m0.2492\u001b[0m  4.0394\n",
      "     37        \u001b[36m0.2381\u001b[0m       \u001b[32m0.9120\u001b[0m        \u001b[35m0.2491\u001b[0m  3.9207\n",
      "     38        \u001b[36m0.2374\u001b[0m       \u001b[32m0.9120\u001b[0m        \u001b[35m0.2488\u001b[0m  4.0290\n",
      "     39        \u001b[36m0.2370\u001b[0m       0.9120        \u001b[35m0.2485\u001b[0m  4.0236\n",
      "     40        \u001b[36m0.2365\u001b[0m       0.9119        \u001b[35m0.2485\u001b[0m  4.0461\n",
      "     41        \u001b[36m0.2359\u001b[0m       \u001b[32m0.9121\u001b[0m        \u001b[35m0.2484\u001b[0m  4.0969\n",
      "     42        \u001b[36m0.2353\u001b[0m       0.9121        \u001b[35m0.2484\u001b[0m  4.0612\n",
      "     43        \u001b[36m0.2349\u001b[0m       0.9119        \u001b[35m0.2483\u001b[0m  3.9845\n",
      "     44        \u001b[36m0.2345\u001b[0m       \u001b[32m0.9122\u001b[0m        \u001b[35m0.2480\u001b[0m  3.9452\n",
      "     45        \u001b[36m0.2340\u001b[0m       \u001b[32m0.9124\u001b[0m        0.2481  3.9619\n",
      "     46        \u001b[36m0.2335\u001b[0m       \u001b[32m0.9125\u001b[0m        \u001b[35m0.2477\u001b[0m  3.9484\n",
      "     47        \u001b[36m0.2331\u001b[0m       0.9123        \u001b[35m0.2476\u001b[0m  3.9482\n",
      "     48        \u001b[36m0.2326\u001b[0m       0.9122        0.2476  3.9605\n",
      "     49        \u001b[36m0.2322\u001b[0m       0.9124        \u001b[35m0.2474\u001b[0m  3.8985\n",
      "     50        \u001b[36m0.2318\u001b[0m       0.9124        \u001b[35m0.2474\u001b[0m  3.8204\n",
      "     51        \u001b[36m0.2314\u001b[0m       0.9124        \u001b[35m0.2472\u001b[0m  3.8612\n",
      "     52        \u001b[36m0.2310\u001b[0m       \u001b[32m0.9125\u001b[0m        \u001b[35m0.2469\u001b[0m  3.8862\n",
      "     53        \u001b[36m0.2306\u001b[0m       \u001b[32m0.9126\u001b[0m        0.2471  3.8100\n",
      "     54        \u001b[36m0.2302\u001b[0m       0.9125        \u001b[35m0.2469\u001b[0m  3.8594\n",
      "     55        \u001b[36m0.2298\u001b[0m       0.9124        \u001b[35m0.2468\u001b[0m  3.8915\n",
      "     56        \u001b[36m0.2295\u001b[0m       0.9123        \u001b[35m0.2468\u001b[0m  3.8849\n",
      "     57        \u001b[36m0.2291\u001b[0m       0.9123        \u001b[35m0.2466\u001b[0m  3.9660\n",
      "     58        \u001b[36m0.2288\u001b[0m       0.9121        0.2467  3.9933\n",
      "     59        \u001b[36m0.2285\u001b[0m       0.9121        \u001b[35m0.2465\u001b[0m  3.9832\n",
      "     60        \u001b[36m0.2281\u001b[0m       0.9123        0.2465  3.9616\n",
      "     61        \u001b[36m0.2278\u001b[0m       0.9122        \u001b[35m0.2465\u001b[0m  4.0040\n",
      "     62        \u001b[36m0.2275\u001b[0m       0.9120        0.2465  3.9831\n",
      "     63        \u001b[36m0.2272\u001b[0m       0.9123        \u001b[35m0.2463\u001b[0m  3.9642\n",
      "     64        \u001b[36m0.2268\u001b[0m       0.9123        \u001b[35m0.2462\u001b[0m  3.9934\n",
      "     65        \u001b[36m0.2265\u001b[0m       0.9123        0.2463  4.0044\n",
      "     66        \u001b[36m0.2262\u001b[0m       0.9124        \u001b[35m0.2462\u001b[0m  3.9742\n",
      "     67        \u001b[36m0.2260\u001b[0m       0.9124        \u001b[35m0.2461\u001b[0m  4.0434\n",
      "     68        \u001b[36m0.2256\u001b[0m       0.9125        \u001b[35m0.2461\u001b[0m  3.9339\n",
      "     69        \u001b[36m0.2253\u001b[0m       0.9125        \u001b[35m0.2460\u001b[0m  4.1942\n",
      "     70        \u001b[36m0.2251\u001b[0m       \u001b[32m0.9126\u001b[0m        \u001b[35m0.2460\u001b[0m  4.1033\n",
      "     71        \u001b[36m0.2248\u001b[0m       \u001b[32m0.9128\u001b[0m        0.2460  4.1765\n",
      "     72        \u001b[36m0.2245\u001b[0m       0.9127        \u001b[35m0.2459\u001b[0m  4.3457\n",
      "     73        \u001b[36m0.2243\u001b[0m       0.9127        \u001b[35m0.2459\u001b[0m  4.4023\n",
      "     74        \u001b[36m0.2240\u001b[0m       0.9127        0.2460  4.3351\n",
      "     75        \u001b[36m0.2237\u001b[0m       \u001b[32m0.9129\u001b[0m        \u001b[35m0.2459\u001b[0m  4.3443\n",
      "     76        \u001b[36m0.2235\u001b[0m       0.9129        0.2460  4.3375\n",
      "     77        \u001b[36m0.2233\u001b[0m       0.9128        0.2460  4.3499\n",
      "     78        \u001b[36m0.2230\u001b[0m       \u001b[32m0.9129\u001b[0m        0.2461  6.1295\n",
      "     79        \u001b[36m0.2227\u001b[0m       0.9129        0.2461  7.6762\n",
      "Stopping since valid_loss has not improved in the last 5 epochs.\n",
      "training set score: 0.9198847973966826\n",
      "Accuracy of class 0: 0.9820917500920351\n",
      "Accuracy of class 1: 0.2834844969415735\n",
      "Accuracy of class 2: 0.901712111604312\n",
      "Accuracy of class 3: 0.3947870311506675\n",
      "Accuracy of class 4: 0.8343253968253969\n",
      "Accuracy of class 5: 0.6764543700027571\n",
      "Accuracy of class 6: 0.35353535353535354\n",
      "testing set score: 0.9116724856784516\n"
     ]
    }
   ],
   "source": [
    "from cnn_builder import *\n",
    "\n",
    "\n",
    "# learning_rate = 2e-2\n",
    "# channel = 32\n",
    "\n",
    "\n",
    "# model_X_normalized = torch.Tensor(model_X)\n",
    "# model_X_normalized = torch.unsqueeze(model_X_normalized, 1)\n",
    "\n",
    "\n",
    "# cnn = CNN_Sleeping(channels = channel)\n",
    "\n",
    "# model = skorch.NeuralNetClassifier(cnn, criterion=torch.nn.CrossEntropyLoss,\n",
    "#                              device=\"cuda\",\n",
    "#                              optimizer=torch.optim.SGD ,\n",
    "#                              lr=learning_rate,\n",
    "#                              max_epochs=120,\n",
    "#                              batch_size=128,\n",
    "#                              callbacks=[skorch.callbacks.EarlyStopping(lower_is_better=True)])\n",
    "\n",
    "# model.fit(model_X_normalized, np.asarray(model_y, dtype=np.int64))\n",
    "\n",
    "train_cnn_model(model_X, model_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 281216\n",
      "1.0 15578\n",
      "2.0 62754\n",
      "3.0 5255\n",
      "4.0 3231\n",
      "5.0 24275\n",
      "6.0 1036\n"
     ]
    }
   ],
   "source": [
    "# distribution of labels y\n",
    "# print every count of labels\n",
    "for i in y_values:\n",
    "    print(i, np.sum(model_y == i))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
